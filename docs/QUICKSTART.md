# Quick Start Guide

## Phase 1 & 2 Complete! âœ…

Wir haben erfolgreich die **Grundlagen und Core-Implementierung** abgeschlossen:

### âœ… Phase 1: Projektstruktur
- VollstÃ¤ndige Verzeichnisstruktur erstellt
- `requirements.txt` mit allen Dependencies
- `setup.py` fÃ¼r Package-Installation
- README mit ProjektÃ¼bersicht

### âœ… Phase 2: Core-Module
Drei essenzielle Module implementiert:

#### 1. **`src/core/precompute.py`** - Î¦(t) und Î£(t) Berechnung
- `build_A_node()` - Konvertiert Graph-Laplacian zu Drift-Matrix
- `precompute_phi_sigma_explicit()` - Berechnet Diffusions-Matrizen
- UnterstÃ¼tzt linear & cosine Î²-schedules
- Diagonal-Approximation fÃ¼r Speicher-Effizienz
- Automatische StabilitÃ¤tsprÃ¼fung

#### 2. **`src/core/forward.py`** - Forward-Noising
- `apply_Phi_node_batch()` - Batch-fÃ¤hige Transformation
- `forward_noising_batch()` - St = Î¦(t)S0 + âˆšÎ£(t)Îµ
- `compute_hat_S0_from_eps_hat()` - Rekonstruktion von Clean-State
- Flexible Zeitschritt-Sampling-Strategien

#### 3. **`src/data/graph_builder.py`** - Graph-Konstruktion
- `build_grid_laplacian()` - 1D/2D/3D Grids mit periodischen BC
- `build_laplacian_from_edges()` - Generische Edge-List zu Laplacian
- `build_molecular_graph()` - 3D Molekular-Strukturen mit Cutoff
- Graph-Statistiken und Visualisierung

#### 4. **`src/core/utils.py`** - Utility-Funktionen
- Normalisierung und Denormalisierung
- Matrix-Operationen (sqrt, Symmetrie-Check)
- EMA und Learning-Rate Scheduling
- Checkpoint-Management

## NÃ¤chste Schritte

### Sofort verfÃ¼gbar:
1. Dependencies installieren: `pip install -r requirements.txt`
2. Package installieren: `pip install -e .`
3. Module testen: `python -m src.core.precompute`

### Phase 3: Modell-Architektur (nÃ¤chste PrioritÃ¤t)
- Epsilon-Netzwerk (Îµ-prediction)
- Graph Neural Network Layers
- Zeit-Embedding

### Phase 4: Training
- Loss-Funktionen
- Physikalische Regularisierer
- Training-Pipeline

## Code-Beispiel

```python
import torch
from src.core.precompute import precompute_phi_sigma_explicit
from src.core.forward import forward_noising_batch, sample_timesteps
from src.data.graph_builder import build_grid_laplacian

# Setup: 5x5 grid, 100 timesteps
L = build_grid_laplacian((5, 5))
Phi, Sigma = precompute_phi_sigma_explicit(L, num_steps=100, diag_approx=True)

# Generate data: 4 samples, 25 nodes, 3 dimensions
S0 = torch.randn(4, 25, 3)

# Sample time steps and apply noising
t_indices = sample_timesteps(4, 100, S0.device)
Phi_t = Phi[t_indices]
Sigma_t = Sigma[t_indices]
St, eps = forward_noising_batch(S0, Phi_t, Sigma_t)

print(f"Clean: {S0.shape}, Noised: {St.shape}, Noise: {eps.shape}")
```

## Projektstruktur

```
3dde/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ formulas.md          âœ… Mathematische Formeln
â”‚   â”œâ”€â”€ aufabenliste.md      âœ… Aufgabenliste (wird aktualisiert)
â”‚   â””â”€â”€ QUICKSTART.md        âœ… Diese Datei
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ precompute.py    âœ… Î¦/Î£ Berechnung
â”‚   â”‚   â”œâ”€â”€ forward.py       âœ… Forward-Noising
â”‚   â”‚   â”œâ”€â”€ utils.py         âœ… Utilities
â”‚   â”‚   â””â”€â”€ sampling.py      â³ NÃ¤chster Schritt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ eps_net.py       â³ Phase 3
â”‚   â”‚   â””â”€â”€ gnn_layers.py    â³ Phase 3
â”‚   â”œâ”€â”€ training/            â³ Phase 4
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ graph_builder.py âœ… Graph-Konstruktion
â”‚   â”‚   â””â”€â”€ dataset.py       â³ SpÃ¤ter
â”‚   â””â”€â”€ tests/               â³ Phase 6
â”œâ”€â”€ requirements.txt         âœ…
â”œâ”€â”€ setup.py                 âœ…
â””â”€â”€ README.md                âœ…
```

## Status

- **Phase 1**: âœ… Komplett (Projektstruktur)
- **Phase 2**: âœ… Komplett (Core-Module)
- **Phase 3**: â³ Bereit zu starten (Modell-Architektur)
- **Phase 4-8**: ğŸ”œ Geplant

## Technische Highlights

### Numerische StabilitÃ¤t
- Automatische KonditionsprÃ¼fung fÃ¼r Î¦-Matrizen
- Regularisierung bei Matrix-Inversionen
- Cholesky-Dekomposition fÃ¼r Î£^(1/2)
- Clipping bei Î²-Schedules

### Effizienz
- Diagonal-Approximation fÃ¼r Î£ (reduziert O(NÂ²) â†’ O(N))
- Batch-fÃ¤hige Matrix-Operationen
- Optional: Sparse-Matrix Support (vorbereitet)

### FlexibilitÃ¤t
- Multiple Î²-Schedules (linear, cosine)
- UnterstÃ¼tzt 1D/2D/3D Graphen
- Generische Laplacian-Konstruktion
- Periodische & offene Randbedingungen

## NÃ¤chster Befehl

Willst du weitermachen mit **Phase 3** (Modell-Architektur)?
Oder sollen wir zuerst die Dependencies installieren und Tests laufen lassen?
